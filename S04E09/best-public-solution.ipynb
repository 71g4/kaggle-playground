{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":76728,"databundleVersionId":9057646,"sourceType":"competition"},{"sourceId":6478229,"sourceType":"datasetVersion","datasetId":3742543},{"sourceId":195994624,"sourceType":"kernelVersion"},{"sourceId":197661496,"sourceType":"kernelVersion"}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"this notebook is the stacking of my highest score's notebook (72040) The main improvement is adding this feature: oof difference between MSE and MAE\n\nand this public notebook[https://www.kaggle.com/code/allegich/price-cars-prediction-eda-blending/notebook#About-this-competition](http://), Thanks a lot! @Allegich\n\nI would greatly appreciate it if you would consider upvote.","metadata":{}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport re\n\nimport lightgbm as lgb\nfrom lightgbm import log_evaluation, early_stopping\nfrom catboost import CatBoostRegressor, Pool\n\nfrom sklearn.svm import SVR\nfrom xgboost import XGBRegressor\n\n\n\nimport random\n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import KFold\n\nimport optuna\n\nUSE_OPTUNA = False","metadata":{"execution":{"iopub.status.busy":"2024-09-14T03:37:49.624837Z","iopub.execute_input":"2024-09-14T03:37:49.62528Z","iopub.status.idle":"2024-09-14T03:37:49.633416Z","shell.execute_reply.started":"2024-09-14T03:37:49.625237Z","shell.execute_reply":"2024-09-14T03:37:49.632378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python /kaggle/usr/lib/lgbm_cat/lgbm_cat.py ","metadata":{"execution":{"iopub.status.busy":"2024-09-14T03:37:49.635546Z","iopub.execute_input":"2024-09-14T03:37:49.635946Z","iopub.status.idle":"2024-09-14T03:37:49.645356Z","shell.execute_reply.started":"2024-09-14T03:37:49.635901Z","shell.execute_reply":"2024-09-14T03:37:49.644227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_1 = pd.read_csv(\"/kaggle/working/submission_1.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-09-14T03:37:49.646757Z","iopub.execute_input":"2024-09-14T03:37:49.647088Z","iopub.status.idle":"2024-09-14T03:37:49.655988Z","shell.execute_reply.started":"2024-09-14T03:37:49.647054Z","shell.execute_reply":"2024-09-14T03:37:49.655021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_2 = pd.read_csv(\"/kaggle/input/price-cars-prediction-eda-blending/submission.csv\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\nsample_sub = pd.read_csv('/kaggle/input/playground-series-s4e9/sample_submission.csv')\ntrain = pd.read_csv('/kaggle/input/playground-series-s4e9/train.csv')\ntest = pd.read_csv('/kaggle/input/playground-series-s4e9/test.csv')\nOriginal = pd.read_csv('/kaggle/input/used-car-price-prediction-dataset/used_cars.csv')\n\ntrain.drop(columns=['id'], inplace=True)\ntest.drop(columns=['id'], inplace=True)\n\nOriginal[['milage', 'price']] = Original[['milage', 'price']].map(\n    lambda x: int(''.join(re.findall(r'\\d+', x))))\n\ntrain = pd.concat([train, Original], ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2024-09-14T03:37:49.65836Z","iopub.execute_input":"2024-09-14T03:37:49.658736Z","iopub.status.idle":"2024-09-14T03:37:50.817603Z","shell.execute_reply.started":"2024-09-14T03:37:49.658701Z","shell.execute_reply":"2024-09-14T03:37:50.816297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def extract_age_features(df):\n    current_year = 2024\n\n    df['Vehicle_Age'] = current_year - df['model_year']\n    \n    df['Mileage_per_Year'] = df['milage'] / df['Vehicle_Age']\n    df['milage_with_age'] =  df.groupby('Vehicle_Age')['milage'].transform('mean')\n    \n    df['Mileage_per_Year_with_age'] =  df.groupby('Vehicle_Age')['Mileage_per_Year'].transform('mean')\n \n#     df['milage_brand'] =  df.groupby('brand')['milage'].transform('mean')\n    \n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2024-09-14T03:37:50.820747Z","iopub.execute_input":"2024-09-14T03:37:50.821088Z","iopub.status.idle":"2024-09-14T03:37:50.827091Z","shell.execute_reply.started":"2024-09-14T03:37:50.821052Z","shell.execute_reply":"2024-09-14T03:37:50.826048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def extract_engine_features(df):\n    \n    def extract_horsepower(engine):\n        try:\n            return float(engine.split('HP')[0])\n        except:\n            return None\n\n    def extract_engine_size(engine):\n        try:\n            return float(engine.split(' ')[1].replace('L', ''))\n        except:\n            return None\n\n    df['Horsepower'] = df['engine'].apply(extract_horsepower)\n    df['Engine_Size'] = df['engine'].apply(extract_engine_size)\n    df['Power_to_Weight_Ratio'] = df['Horsepower'] / df['Engine_Size']\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2024-09-14T03:37:50.828719Z","iopub.execute_input":"2024-09-14T03:37:50.829258Z","iopub.status.idle":"2024-09-14T03:37:50.839077Z","shell.execute_reply.started":"2024-09-14T03:37:50.829218Z","shell.execute_reply":"2024-09-14T03:37:50.838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def extract_other_features(df):\n    \n    luxury_brands =  ['Mercedes-Benz', 'BMW', 'Audi', 'Porsche', 'Land', \n                    'Lexus', 'Jaguar', 'Bentley', 'Maserati', 'Lamborghini', \n                    'Rolls-Royce', 'Ferrari', 'McLaren', 'Aston', 'Maybach']\n    df['Is_Luxury_Brand'] = df['brand'].apply(lambda x: 1 if x in luxury_brands else 0)\n    \n#     df['luxary_with_accident'] = df.apply(lambda row: 1 if row['Is_Luxury_Brand'] == 1  and row['accident'] == 'At least 1 accident or damage reported' else 0  ,  axis =1)\n    \n#     df.drop(columns = ['Is_Luxury_Brand'] , inplace=True)\n\n\n\n    return df","metadata":{"execution":{"iopub.status.busy":"2024-09-14T03:37:50.843343Z","iopub.execute_input":"2024-09-14T03:37:50.843697Z","iopub.status.idle":"2024-09-14T03:37:50.850226Z","shell.execute_reply.started":"2024-09-14T03:37:50.843656Z","shell.execute_reply":"2024-09-14T03:37:50.849173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\ntrain = extract_age_features(train)\ntest = extract_age_features(test)\n\n# train = extract_engine_features(train)\n# test = extract_engine_features(test)\n\ntrain = extract_other_features(train)\ntest = extract_other_features(test)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-14T03:37:50.851922Z","iopub.execute_input":"2024-09-14T03:37:50.852276Z","iopub.status.idle":"2024-09-14T03:37:51.159847Z","shell.execute_reply.started":"2024-09-14T03:37:50.852244Z","shell.execute_reply":"2024-09-14T03:37:51.158609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2024-09-14T03:37:51.162315Z","iopub.execute_input":"2024-09-14T03:37:51.162737Z","iopub.status.idle":"2024-09-14T03:37:51.199307Z","shell.execute_reply.started":"2024-09-14T03:37:51.16269Z","shell.execute_reply":"2024-09-14T03:37:51.198088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def update(df):\n    \n    t = 100\n    \n    cat_c = ['brand','model','fuel_type','engine','transmission','ext_col','int_col','accident','clean_title',\n             \n            ]\n    re_ = ['model','engine','transmission','ext_col','int_col']\n    \n    for col in re_:\n        df.loc[df[col].value_counts(dropna=False)[df[col]].values < t, col] = \"noise\"\n        \n    for col in cat_c:\n        df[col] = df[col].fillna('missing')\n        df[col] = df[col].astype('category')\n        \n    return df\n\ntrain  = update(train)\ntest   = update(test)\n\nX = train.drop('price', axis=1)\ny = train['price']","metadata":{"execution":{"iopub.status.busy":"2024-09-14T03:37:51.20452Z","iopub.execute_input":"2024-09-14T03:37:51.205374Z","iopub.status.idle":"2024-09-14T03:37:52.321242Z","shell.execute_reply.started":"2024-09-14T03:37:51.20532Z","shell.execute_reply":"2024-09-14T03:37:52.320105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport lightgbm as lgb\nfrom catboost import CatBoostRegressor, Pool\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import KFold\n\n\n\ncallbacks = [log_evaluation(period=300), early_stopping(stopping_rounds=200)]\n\ncat_cols = train.select_dtypes(include=['object', 'category']).columns.tolist()\n\nprint(f\"cat_cols--------{cat_cols}\")\n\n\ndef get_MAE_oof(df, target, lgb_params, cat_params=None, model_type='LGBM'):\n\n    \n    oof_predictions = np.zeros(len(df))\n    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n    models = []\n    rmse_scores = []\n    \n    for fold, (train_idx, val_idx) in enumerate(kf.split(df)):\n        print(f\"Training fold {fold + 1}/{5} with {model_type}\")\n\n        X_train, X_val = df.iloc[train_idx], df.iloc[val_idx]\n        y_train, y_val = target.iloc[train_idx], target.iloc[val_idx]\n\n        if model_type == 'LGBM':\n            train_data = lgb.Dataset(X_train, label=y_train)\n            val_data = lgb.Dataset(X_val, label=y_val, reference=train_data)\n            \n            model = lgb.train(\n                lgb_params,\n                train_data,\n                valid_sets=[train_data, val_data],\n                valid_names=['train', 'valid'],\n                callbacks=callbacks    \n            )\n        \n        elif model_type == 'CAT':\n            train_data = Pool(data=X_train, label=y_train , cat_features=cat_cols)\n            val_data = Pool(data=X_val, label=y_val , cat_features=cat_cols )\n            \n            model = CatBoostRegressor(**cat_params)\n            model.fit(train_data, eval_set=val_data, verbose=150, early_stopping_rounds=200)\n        \n        models.append(model)\n        \n        if model_type == 'LGBM':\n            pred = model.predict(X_val, num_iteration=model.best_iteration)\n        elif model_type == 'CAT':\n            pred = model.predict(X_val)\n        \n        rmse = np.sqrt(mean_squared_error(y_val, pred))\n        rmse_scores.append(rmse)\n\n        print(f'{model_type} Fold RMSE: {rmse}')\n        \n        oof_predictions[val_idx] = pred\n        \n    print(f'Mean RMSE: {np.mean(rmse_scores)}')\n    return oof_predictions, models\n\n\n\n\nlgb_params = {\n    'objective': 'MAE',\n    'n_estimators': 1000,\n    'random_state': 42,\n}\n\noof_predictions_lgbm, models_lgbm = get_MAE_oof(X, y, lgb_params, model_type='LGBM')\nX['LGBM_MAE'] = oof_predictions_lgbm\n\n\nLGBM_preds = np.zeros(len(test))\nfor model in models_lgbm:\n    LGBM_preds += model.predict(test) / len(models_lgbm)\ntest['LGBM_MAE'] = LGBM_preds\n\n\n\nlgb_params = {\n    'objective': 'MSE',\n    'n_estimators': 1000,\n    'random_state': 42,\n}\n\noof_predictions_lgbm, models_lgbm = get_MAE_oof(X, y, lgb_params, model_type='LGBM')\n\nX['LGBM_MSE_diff'] = oof_predictions_lgbm - X['LGBM_MAE']\n\n\nLGBM_preds = np.zeros(len(test))\nfor model in models_lgbm:\n    LGBM_preds += model.predict(test) / len(models_lgbm)\ntest['LGBM_MSE_diff'] = LGBM_preds - test['LGBM_MAE']","metadata":{"execution":{"iopub.status.busy":"2024-09-14T03:37:52.322765Z","iopub.execute_input":"2024-09-14T03:37:52.323222Z","iopub.status.idle":"2024-09-14T03:38:53.110352Z","shell.execute_reply.started":"2024-09-14T03:37:52.323169Z","shell.execute_reply":"2024-09-14T03:38:53.109376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef objective_lgb(trial):   \n    lgb_params = {\n        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n        'max_depth': trial.suggest_int('max_depth', 5, 50),\n        'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-4, 1.0),\n        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-4, 10.0),\n        'num_leaves': trial.suggest_int('num_leaves', 20, 150),\n        'subsample': trial.suggest_uniform('subsample', 0.2, 1.0),\n        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.2, 1.0),\n        'n_estimators': 1000,\n        'random_state': 42\n    }\n\n    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n    rmse_scores = []\n\n    for train_index, val_index in kf.split(X):\n        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n        y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n\n        train_data = lgb.Dataset(X_train, label=y_train)\n        val_data = lgb.Dataset(X_val, label=y_val, reference=train_data)\n\n        model = lgb.train(lgb_params, \n                          train_data, \n                          valid_sets=[val_data], \n                          callbacks=callbacks\n                         )\n\n        y_pred = model.predict(X_val)\n        rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n        rmse_scores.append(rmse)\n\n    return np.mean(rmse_scores)\n\ndef objective_cat(trial):\n\n    cat_params = {\n        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n        'depth': trial.suggest_int('depth', 5, 16),\n        'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-4, 10.0),\n        'iterations': 1000,\n        'random_strength': trial.suggest_int('random_strength', 0, 100),\n        'cat_features': cat_cols,\n        'random_seed': 42,\n        'task_type': 'GPU',\n        'early_stopping_rounds': 200\n    }\n\n    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n    rmse_scores_cat = []\n\n    for train_index, val_index in kf.split(X):\n        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n        y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n        \n        train_pool = Pool(X_train, y_train, cat_features=cat_cols)\n        val_pool = Pool(X_val, y_val, cat_features=cat_cols)\n        \n        model_cat = CatBoostRegressor(**cat_params)\n        model_cat.fit(train_pool, eval_set=val_pool, verbose=300)\n        \n        y_pred_cat = model_cat.predict(X_val)\n        rmse_cat = np.sqrt(mean_squared_error(y_val, y_pred_cat))\n        rmse_scores_cat.append(rmse_cat)\n    \n    return np.mean(rmse_scores_cat)\n\nif USE_OPTUNA==True:\n    study_lgb = optuna.create_study(direction='minimize')\n    study_lgb.optimize(objective_lgb, n_trials=20)\n\n    print(\"Best LGBM Parameters: \", study_lgb.best_params)\n    print(\"Best LGBM RMSE: \", study_lgb.best_value)\n\n    study_cat = optuna.create_study(direction='minimize')\n    study_cat.optimize(objective_cat, n_trials=2)\n\n    print(\"Best CatBoost Parameters: \", study_cat.best_params)\n    print(\"Best CatBoost RMSE: \", study_cat.best_value)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-14T03:38:53.112075Z","iopub.execute_input":"2024-09-14T03:38:53.112763Z","iopub.status.idle":"2024-09-14T03:38:53.132949Z","shell.execute_reply.started":"2024-09-14T03:38:53.112717Z","shell.execute_reply":"2024-09-14T03:38:53.132137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lgb_params_1 ={\n\n    'learning_rate': 0.017521301504983752,\n    'max_depth': 42,\n    'reg_alpha': 0.06876635751774487, \n    'reg_lambda': 9.738899198284985,\n    'num_leaves': 131,\n    'subsample': 0.2683765421728044,\n    'colsample_bytree': 0.44346036599709887,\n    'n_estimators': 1000,\n    'random_state': 42,\n    'extra_tree' : True,\n    'verbose' : -1\n}\n\nlgb_params_2 ={\n\n    'learning_rate': 0.017521301504983752,\n    'max_depth': 42,\n    'reg_alpha': 0.06876635751774487, \n    'reg_lambda': 9.738899198284985,\n    'num_leaves': 131,\n    'subsample': 0.2683765421728044,\n    'colsample_bytree': 0.44346036599709887,\n    'n_estimators': 1000,\n    'random_state': 42,\n    'verbose' : -1\n}\n\ncat_params={\n    'learning_rate':0.042,\n    'iterations':1000,\n    'depth':10,\n    'random_strength' : 10,\n    'cat_features':cat_cols,\n    'l2_leaf_reg':0.3,\n    'random_seed':42,\n    'early_stopping_rounds': 200,\n    'task_type':'GPU',\n}\n\n\n\nkf = KFold(n_splits=5, shuffle=True, random_state=42)\n\nrmse_scores = []\nrmse_scores_cat = []\nLGBM_model=[]\nCAT_model =[]\n\ncallbacks = [log_evaluation(period=150), early_stopping(stopping_rounds=200)]\n\nfor train_index, val_index in kf.split(X):\n    X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n    \n\n    \n    train_data = lgb.Dataset(X_train, label=y_train)\n    val_data = lgb.Dataset(X_val, label=y_val, reference=train_data)\n    \n    model_1 = lgb.train(lgb_params_1,\n                      train_data,\n                      valid_sets=[train_data, val_data],\n                      valid_names=['train', 'valid'],\n                      callbacks=callbacks        \n                      )\n    model_2 = lgb.train(lgb_params_2,\n                  train_data,\n                  valid_sets=[train_data, val_data],\n                  valid_names=['train', 'valid'],\n                  callbacks=callbacks        \n                  )\n    \n    LGBM_model.append(model_1)\n    LGBM_model.append(model_2)\n\n    y_pred = model_1.predict(X_val) * 0.5 + model_2.predict(X_val) * 0.5\n    \n\n    rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n    rmse_scores.append(rmse)\n    \n    print(f'LGBM Fold RMSE: {rmse}')\n    \n    \n    model_cat = CatBoostRegressor(**cat_params)\n    \n\n    train_pool = Pool(X_train, y_train ,cat_features=cat_cols)\n    val_pool = Pool(X_val, y_val , cat_features=cat_cols)\n    model_cat.fit(train_pool, eval_set=val_pool, verbose=300)\n    \n    CAT_model.append(model_cat)\n    y_pred_cat = model_cat.predict(X_val)\n    rmse_cat = np.sqrt(mean_squared_error(y_val, y_pred_cat))\n    rmse_scores_cat.append(rmse_cat)\n    \n    print(f'CAT Fold RMSE: {rmse_cat}')\n\n\nprint(f'Mean LGBM RMSE: {np.mean(rmse_scores)}')\nprint(f'Mean CAT RMSE: {np.mean(rmse_scores_cat)}')","metadata":{"execution":{"iopub.status.busy":"2024-09-14T03:38:53.134656Z","iopub.execute_input":"2024-09-14T03:38:53.135306Z","iopub.status.idle":"2024-09-14T03:42:02.324191Z","shell.execute_reply.started":"2024-09-14T03:38:53.135265Z","shell.execute_reply":"2024-09-14T03:42:02.322993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LGBM_preds = np.zeros(len(test))\nfor model in LGBM_model:\n    LGBM_preds += model.predict(test) / len(LGBM_model)","metadata":{"execution":{"iopub.status.busy":"2024-09-14T03:42:02.325728Z","iopub.execute_input":"2024-09-14T03:42:02.32621Z","iopub.status.idle":"2024-09-14T03:42:23.667237Z","shell.execute_reply.started":"2024-09-14T03:42:02.326131Z","shell.execute_reply":"2024-09-14T03:42:23.666229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CAT_preds = np.zeros(len(test))\nfor model in CAT_model:\n    CAT_preds += model.predict(test) / len(CAT_model)","metadata":{"execution":{"iopub.status.busy":"2024-09-14T03:42:23.668988Z","iopub.execute_input":"2024-09-14T03:42:23.669775Z","iopub.status.idle":"2024-09-14T03:42:26.235112Z","shell.execute_reply.started":"2024-09-14T03:42:23.669725Z","shell.execute_reply":"2024-09-14T03:42:26.234042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_preds = LGBM_preds * 0.8 + CAT_preds * 0.2","metadata":{"execution":{"iopub.status.busy":"2024-09-14T03:42:26.236538Z","iopub.execute_input":"2024-09-14T03:42:26.236958Z","iopub.status.idle":"2024-09-14T03:42:26.242866Z","shell.execute_reply.started":"2024-09-14T03:42:26.236913Z","shell.execute_reply":"2024-09-14T03:42:26.241745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_sub['price'] = (0.9 * test_preds + 0.1 * sub_1['price']) * 0.4 + 0.6 * sub_2['price']\nsample_sub.to_csv(\"submission.csv\", index=False)\nsample_sub.head()","metadata":{"execution":{"iopub.status.busy":"2024-09-14T03:42:26.244489Z","iopub.execute_input":"2024-09-14T03:42:26.244945Z","iopub.status.idle":"2024-09-14T03:42:26.29404Z","shell.execute_reply.started":"2024-09-14T03:42:26.244898Z","shell.execute_reply":"2024-09-14T03:42:26.292579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_names = X.columns\n\n\nlgb_importances = np.zeros(len(feature_names))\n\nfor model in LGBM_model:\n    lgb_importances += model.feature_importance(importance_type='split') / len(LGBM_model)\n\nlgb_feature_importance = pd.DataFrame({'Feature': feature_names, 'Importance': lgb_importances})\nlgb_feature_importance.sort_values(by='Importance', ascending=False, inplace=True)\n\n\nprint(lgb_feature_importance)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-14T03:43:07.225117Z","iopub.execute_input":"2024-09-14T03:43:07.226085Z","iopub.status.idle":"2024-09-14T03:43:07.241511Z","shell.execute_reply.started":"2024-09-14T03:43:07.226039Z","shell.execute_reply":"2024-09-14T03:43:07.240413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_names = X.columns\ncat_importances = np.zeros(len(feature_names))\n\nfor model in CAT_model:\n \n    cat_importances += model.get_feature_importance(type='FeatureImportance') / len(CAT_model)\n\ncat_feature_importance = pd.DataFrame({'Feature': feature_names, 'Importance': cat_importances})\ncat_feature_importance.sort_values(by='Importance', ascending=False, inplace=True)\n\n\nprint(cat_feature_importance)","metadata":{"execution":{"iopub.status.busy":"2024-09-14T03:43:09.912354Z","iopub.execute_input":"2024-09-14T03:43:09.913173Z","iopub.status.idle":"2024-09-14T03:43:09.999984Z","shell.execute_reply.started":"2024-09-14T03:43:09.913113Z","shell.execute_reply":"2024-09-14T03:43:09.99896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.hist(sample_sub['price'])","metadata":{"execution":{"iopub.status.busy":"2024-09-14T03:42:26.300032Z","iopub.status.idle":"2024-09-14T03:42:26.300873Z","shell.execute_reply.started":"2024-09-14T03:42:26.300603Z","shell.execute_reply":"2024-09-14T03:42:26.300632Z"},"trusted":true},"execution_count":null,"outputs":[]}]}